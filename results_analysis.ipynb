{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 57,
   "id": "671b1170",
   "metadata": {},
   "outputs": [],
   "source": [
    "import json\n",
    "import pandas as pd\n",
    "import copy\n",
    "import numpy as np\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "id": "7eba4deb",
   "metadata": {},
   "outputs": [],
   "source": [
    "with open('predict_properties/test_predictions.json', 'r') as res_file:\n",
    "        results_dict = json.load(res_file)\n",
    "\n",
    "with open('data/normalisation_stats.json', 'r') as norm_file:\n",
    "        norm_dict = json.load(norm_file)\n",
    "\n",
    "base_values = pd.read_csv('data/test_values.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 68,
   "id": "2a004324",
   "metadata": {},
   "outputs": [],
   "source": [
    "def avg_predictions(dictionary):\n",
    "    predictions_averaged = {}\n",
    "\n",
    "    for smiles, properties in dictionary.items():\n",
    "        predictions_averaged[smiles] = {}\n",
    "\n",
    "        for prop, indices in properties.items():\n",
    "            total_sum = 0\n",
    "            total_count = 0\n",
    "            \n",
    "            # Calculate the sum and count of all predictions\n",
    "            for index, prediction_list in indices.items():\n",
    "                total_sum += sum(prediction_list)\n",
    "                total_count += len(prediction_list)\n",
    "            \n",
    "            # Calculate the average, handling the case where total_count is zero to prevent division by zero\n",
    "            if total_count > 0:\n",
    "                average_prediction = total_sum / total_count\n",
    "            else:\n",
    "                average_prediction = 0 # or None, depending on desired behavior\n",
    "            \n",
    "            predictions_averaged[smiles][prop] = average_prediction\n",
    "    return predictions_averaged\n",
    "    \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "id": "48b6954b",
   "metadata": {},
   "outputs": [],
   "source": [
    "true_values_dict = {}\n",
    "\n",
    "# Use df.itertuples() for a memory-efficient way to iterate over DataFrame rows.\n",
    "# 'index=False' prevents the row index from being included in the tuple.\n",
    "for row in base_values.itertuples(index=False):\n",
    "    # The first element of the tuple is the SMILES string\n",
    "    smiles = row[1]\n",
    "    \n",
    "    # Initialize a new dictionary for this SMILES if it doesn't exist\n",
    "    if smiles not in true_values_dict:\n",
    "        true_values_dict[smiles] = {}\n",
    "        \n",
    "    # Iterate through the rest of the columns to get the properties and values\n",
    "    # We slice the row tuple from the second element (index 1) onwards.\n",
    "    # We also get the corresponding column names from df.columns, excluding 'SMILES'.\n",
    "    for prop_name, value in zip(base_values.columns[1:], row[1:]):\n",
    "        # Store the value in the nested dictionary\n",
    "        true_values_dict[smiles][prop_name] = value\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "id": "81bd26e9",
   "metadata": {},
   "outputs": [],
   "source": [
    "def unnormalize_dict(data_dict, stats):\n",
    "    \"\"\"\n",
    "    Unnormalizes the values in a nested dictionary using z-score statistics.\n",
    "\n",
    "    Args:\n",
    "        data_dict (dict): The nested dictionary with normalized values.\n",
    "                          Format: {smiles: {property: value}}\n",
    "        stats (dict): The dictionary containing mean and std for each property.\n",
    "                      Format: {property: {'mean': value, 'std': value}}\n",
    "\n",
    "    Returns:\n",
    "        dict: A new dictionary with unnormalized values.\n",
    "    \"\"\"\n",
    "    unnormalized_data = copy.deepcopy(data_dict)\n",
    "    \n",
    "    # Iterate through each smiles string in the dictionary\n",
    "    for smiles, properties in unnormalized_data.items():\n",
    "        # Iterate through each property and its normalized value\n",
    "        for prop, value in properties.items():\n",
    "            try:\n",
    "                mean = stats[prop]['mean']\n",
    "                std = stats[prop]['std']\n",
    "                \n",
    "                # Apply the reverse z-score formula: x = (z * std) + mean\n",
    "                unnormalized_value = (value * std) + mean\n",
    "                \n",
    "                # Update the value in the new dictionary\n",
    "                unnormalized_data[smiles][prop] = unnormalized_value\n",
    "            except KeyError:\n",
    "                print(f\"Warning: Statistics not found for property '{prop}'. Skipping unnormalization for this property.\")\n",
    "                # If stats are not found, we keep the original value\n",
    "                unnormalized_data[smiles][prop] = value\n",
    "            \n",
    "    return unnormalized_data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "id": "44aacf00",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Warning: Statistics not found for property 'SMILES'. Skipping unnormalization for this property.\n",
      "Warning: Statistics not found for property 'SMILES'. Skipping unnormalization for this property.\n",
      "Warning: Statistics not found for property 'SMILES'. Skipping unnormalization for this property.\n",
      "Warning: Statistics not found for property 'SMILES'. Skipping unnormalization for this property.\n",
      "Warning: Statistics not found for property 'SMILES'. Skipping unnormalization for this property.\n",
      "41.1042669770486\n",
      "dict_keys(['Fc1c(F)c(F)c(F)c(F)c1F', 'CCCCOCCCC', 'CC1COC(=O)O1', 'CCCC#N', 'NC=O'])\n"
     ]
    }
   ],
   "source": [
    "prediction_avg_unnorm = unnormalize_dict(predictions_averaged, norm_dict)\n",
    "true_values_dict_unorm = unnormalize_dict(true_values_dict, norm_dict)\n",
    "print(prediction_avg_unnorm['CCCC#N']['ET30'])\n",
    "print(true_values_dict_unorm.keys())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "id": "b9c40b63",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                             ET30       delta     alpha        SA  \\\n",
      "CCCC#N                   1.948071    0.206529  0.000544  0.000233   \n",
      "CC1COC(=O)O1            57.116130   71.389598  0.000619  0.007849   \n",
      "Fc1c(F)c(F)c(F)c(F)c1F   2.828682    0.080920  0.000864  0.000096   \n",
      "NC=O                    45.390906  173.220189  0.012045  0.063860   \n",
      "CCCCOCCCC                4.641354    0.967948  0.000217  0.000105   \n",
      "Average_per_property    22.385029   49.173037  0.002858  0.014429   \n",
      "\n",
      "                           N_mol_cm3      beta        SB        fn       SdP  \\\n",
      "CCCC#N                  1.154671e-07  0.002269  0.000312  0.000012  0.000032   \n",
      "CC1COC(=O)O1            1.611648e-06  0.001517  0.010645  0.000265  0.104825   \n",
      "Fc1c(F)c(F)c(F)c(F)c1F  1.982280e-06  0.003618  0.003100  0.007477  0.016309   \n",
      "NC=O                    8.203328e-05  0.059024  0.069810  0.000383  0.000516   \n",
      "CCCCOCCCC               1.193025e-06  0.046849  0.010296  0.000001  0.016412   \n",
      "Average_per_property    1.738714e-05  0.022656  0.018833  0.001628  0.027619   \n",
      "\n",
      "                         pi_star         n        SP  Average_per_solvent  \n",
      "CCCC#N                  0.003510  0.000139  0.000001             0.180138  \n",
      "CC1COC(=O)O1            0.078115  0.000598  0.004194            10.726196  \n",
      "Fc1c(F)c(F)c(F)c(F)c1F  0.060147  0.022644  0.043367             0.255602  \n",
      "NC=O                    0.014488  0.001169  0.009252            18.236810  \n",
      "CCCCOCCCC               0.002289  0.000015  0.000035             0.473794  \n",
      "Average_per_property    0.031710  0.004913  0.011370             5.974508  \n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "\n",
    "def mse_dataframe_with_avgs(pred_dict, true_dict):\n",
    "    # Compute MSE table\n",
    "    data = {}\n",
    "    for smiles, pred_props in pred_dict.items():\n",
    "        data[smiles] = {}\n",
    "        for prop, pred_value in pred_props.items():\n",
    "            true_value = true_dict[smiles][prop]\n",
    "            mse = (pred_value - true_value) ** 2\n",
    "            data[smiles][prop] = mse\n",
    "    df = pd.DataFrame.from_dict(data, orient='index')\n",
    "    \n",
    "    # Add per-row mean (average MSE per solvent)\n",
    "    df[\"Average_per_solvent\"] = df.mean(axis=1)\n",
    "    \n",
    "    # Add per-column mean (average MSE per property)\n",
    "    avg_row = df.mean(axis=0)\n",
    "    \n",
    "    # The intersection of averages = overall average MSE\n",
    "    avg_row[\"Average_per_solvent\"] = avg_row.mean()\n",
    "    \n",
    "    # Append the averages row\n",
    "    df.loc[\"Average_per_property\"] = avg_row\n",
    "    \n",
    "    return df\n",
    "\n",
    "# Example usage:\n",
    "df_mse = mse_dataframe_with_avgs(prediction_avg_unnorm, true_values_dict_unorm)\n",
    "print(df_mse)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 70,
   "id": "2815c591",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                             ET30       delta     alpha        SA  \\\n",
      "CCCC#N                   1.833297    0.231071  0.000546  0.000234   \n",
      "CC1COC(=O)O1            58.325678   72.462646  0.000543  0.007967   \n",
      "Fc1c(F)c(F)c(F)c(F)c1F   2.965540    0.094869  0.000540  0.000051   \n",
      "NC=O                    43.324599  177.425504  0.005476  0.054523   \n",
      "CCCCOCCCC                4.817030    1.025124  0.000194  0.000087   \n",
      "Average_per_property    22.253229   50.247843  0.001460  0.012572   \n",
      "\n",
      "                           N_mol_cm3      beta        SB        fn       SdP  \\\n",
      "CCCC#N                  2.017002e-07  0.002263  0.000347  0.000011  0.000073   \n",
      "CC1COC(=O)O1            3.182043e-06  0.000103  0.004633  0.000308  0.123673   \n",
      "Fc1c(F)c(F)c(F)c(F)c1F  8.497811e-07  0.003982  0.002409  0.007107  0.025870   \n",
      "NC=O                    8.734540e-05  0.042954  0.043525  0.000552  0.002419   \n",
      "CCCCOCCCC               1.351340e-06  0.044822  0.009980  0.000002  0.017944   \n",
      "Average_per_property    1.858605e-05  0.018825  0.012179  0.001596  0.033996   \n",
      "\n",
      "                         pi_star         n        SP  Average_per_solvent  \n",
      "CCCC#N                  0.003698  0.000138  0.000001             0.172640  \n",
      "CC1COC(=O)O1            0.085742  0.000687  0.004587            10.918047  \n",
      "Fc1c(F)c(F)c(F)c(F)c1F  0.071152  0.020783  0.042937             0.269603  \n",
      "NC=O                    0.020089  0.001501  0.011202            18.411036  \n",
      "CCCCOCCCC               0.002315  0.000013  0.000034             0.493129  \n",
      "Average_per_property    0.036599  0.004624  0.011752             6.052891  \n"
     ]
    }
   ],
   "source": [
    "with open('predict_properties/template_results.json', 'r') as template_file:\n",
    "        temp_dict = json.load(template_file)\n",
    "temp_avg = avg_predictions(temp_dict)\n",
    "\n",
    "temp_unnorm = unnormalize_dict(temp_avg, norm_dict)\n",
    "df_mse_temp = mse_dataframe_with_avgs(temp_unnorm, true_values_dict_unorm)\n",
    "print(df_mse_temp)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 71,
   "id": "9db3c9d7",
   "metadata": {},
   "outputs": [],
   "source": [
    "import json\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "import os\n",
    "\n",
    "def compare_predictions_by_n(dict_1, dict_2, ground_truth=None,\n",
    "                           label1='Dataset 1', label2='Dataset 2', output_dir='plots'):\n",
    "    \"\"\"\n",
    "    Create plots comparing predictions for each property from two different datasets,\n",
    "    with optional ground truth values plotted as horizontal lines.\n",
    "\n",
    "    Args:\n",
    "        json_file_path1 (str): Path to the first JSON file containing the data\n",
    "        json_file_path2 (str): Path to the second JSON file containing the data\n",
    "        ground_truth (dict): Dictionary mapping property names to their ground truth values\n",
    "        label1 (str): Label for the first dataset (default: 'Dataset 1')\n",
    "        label2 (str): Label for the second dataset (default: 'Dataset 2')\n",
    "        output_dir (str): Directory to save the plots (default: 'plots')\n",
    "    \"\"\"\n",
    "    # Load data from both JSON files\n",
    "    \n",
    "    data1 = dict_1\n",
    "\n",
    "    data2 = dict_2\n",
    "\n",
    "    # Create output directory if it doesn't exist\n",
    "    os.makedirs(output_dir, exist_ok=True)\n",
    "\n",
    "    # Get all property names from both datasets\n",
    "    all_properties = set(data1.keys()) | set(data2.keys())\n",
    "\n",
    "    # Process each property\n",
    "    for property_name in all_properties:\n",
    "        plt.figure(figsize=(12, 8))\n",
    "\n",
    "        # Initialize variables to track x-axis range\n",
    "        all_n_values = []\n",
    "\n",
    "        # Process first dataset if property exists\n",
    "        if property_name in data1:\n",
    "            property_data1 = data1[property_name]\n",
    "\n",
    "            # Prepare data for plotting\n",
    "            n_values1 = []\n",
    "            means1 = []\n",
    "            std_devs1 = []\n",
    "            mins1 = []\n",
    "            maxs1 = []\n",
    "\n",
    "            # Sort n values numerically\n",
    "            sorted_ns1 = sorted(map(int, property_data1.keys()))\n",
    "\n",
    "            for n in sorted_ns1:\n",
    "                n_str = str(n)\n",
    "                values = property_data1[n_str]\n",
    "                n_values1.append(n)\n",
    "                means1.append(np.mean(values))\n",
    "                std_devs1.append(np.std(values))\n",
    "                mins1.append(min(values))\n",
    "                maxs1.append(max(values))\n",
    "\n",
    "            all_n_values.extend(n_values1)\n",
    "\n",
    "            # Plot first dataset\n",
    "            plt.errorbar(n_values1, means1, yerr=std_devs1, fmt='-o',\n",
    "                        capsize=5, capthick=2, label=f'{label1} Mean ± Std Dev',\n",
    "                        color='blue', alpha=0.8)\n",
    "\n",
    "            plt.fill_between(n_values1, mins1, maxs1, alpha=0.15,\n",
    "                            label=f'{label1} Min/Max Range', color='blue')\n",
    "\n",
    "        # Process second dataset if property exists\n",
    "        if property_name in data2:\n",
    "            property_data2 = data2[property_name]\n",
    "\n",
    "            # Prepare data for plotting\n",
    "            n_values2 = []\n",
    "            means2 = []\n",
    "            std_devs2 = []\n",
    "            mins2 = []\n",
    "            maxs2 = []\n",
    "\n",
    "            # Sort n values numerically\n",
    "            sorted_ns2 = sorted(map(int, property_data2.keys()))\n",
    "\n",
    "            for n in sorted_ns2:\n",
    "                n_str = str(n)\n",
    "                values = property_data2[n_str]\n",
    "                n_values2.append(n)\n",
    "                means2.append(np.mean(values))\n",
    "                std_devs2.append(np.std(values))\n",
    "                mins2.append(min(values))\n",
    "                maxs2.append(max(values))\n",
    "\n",
    "            all_n_values.extend(n_values2)\n",
    "\n",
    "            # Plot second dataset\n",
    "            plt.errorbar(n_values2, means2, yerr=std_devs2, fmt='-s',\n",
    "                        capsize=5, capthick=2, label=f'{label2} Mean ± Std Dev',\n",
    "                        color='red', alpha=0.8)\n",
    "\n",
    "            plt.fill_between(n_values2, mins2, maxs2, alpha=0.15,\n",
    "                            label=f'{label2} Min/Max Range', color='red')\n",
    "\n",
    "        # Plot ground truth if provided\n",
    "        if ground_truth and property_name in ground_truth:\n",
    "            # Get the range of x values to draw the line across the entire plot\n",
    "            x_range = sorted(set(all_n_values))\n",
    "            if x_range:\n",
    "                x_min, x_max = min(x_range), max(x_range)\n",
    "                # Add some padding to the line\n",
    "                x_padding = (x_max - x_min) * 0.05 if x_max > x_min else 0.5\n",
    "                x_line = [x_min - x_padding, x_max + x_padding]\n",
    "                y_line = [ground_truth[property_name], ground_truth[property_name]]\n",
    "\n",
    "                plt.plot(x_line, y_line, '--', color='green', linewidth=2,\n",
    "                        label=f'Ground Truth ({ground_truth[property_name]:.3f})', alpha=0.8)\n",
    "\n",
    "        # Handle case where property only exists in one dataset\n",
    "        if property_name not in data1:\n",
    "            print(f\"Warning: Property '{property_name}' not found in {dict_1}\")\n",
    "        elif property_name not in data2:\n",
    "            print(f\"Warning: Property '{property_name}' not found in {dict_2}\")\n",
    "\n",
    "        # Handle case where ground truth is provided but property not found\n",
    "        if ground_truth and property_name not in ground_truth:\n",
    "            print(f\"Warning: Ground truth value for '{property_name}' not provided\")\n",
    "\n",
    "        # Customize plot\n",
    "        title = f'Prediction Comparison for {property_name} by Position n\\n{label1} vs {label2}'\n",
    "        if ground_truth and property_name in ground_truth:\n",
    "            title += f' (Ground Truth: {ground_truth[property_name]:.3f})'\n",
    "        plt.title(title)\n",
    "        plt.xlabel('Prediction Position (n)')\n",
    "        plt.ylabel('Prediction Value')\n",
    "\n",
    "        # Set x-ticks to show all n values from both datasets\n",
    "        unique_n_values = sorted(set(all_n_values))\n",
    "        if unique_n_values:\n",
    "            plt.xticks(unique_n_values)\n",
    "        plt.grid(True, linestyle='--', alpha=0.6)\n",
    "        plt.legend()\n",
    "\n",
    "        # Save plot\n",
    "        plot_filename = os.path.join(output_dir, f'{property_name}_comparison.png')\n",
    "        plt.savefig(plot_filename, bbox_inches='tight', dpi=300)\n",
    "        plt.close()\n",
    "\n",
    "        print(f'Saved comparison plot for {property_name} to {plot_filename}')\n",
    "\n",
    "# Example usage:\n",
    "# ground_truth_values = {\n",
    "#     'property1': 2.5,\n",
    "#     'property2': 1.8,\n",
    "#     'property3': 3.2\n",
    "# }\n",
    "#\n",
    "# compare_predictions_by_n('/path/to/first_dataset.json', '/path/to/second_dataset.json',\n",
    "#                         ground_truth=ground_truth_values,\n",
    "#                         label1='Original Model', label2='Fine-tuned Model')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 82,
   "id": "7bc4bc12",
   "metadata": {},
   "outputs": [],
   "source": [
    "import copy\n",
    "\n",
    "def unnormalize_dict_with_lists(data_dict, stats):\n",
    "    \"\"\"\n",
    "    Unnormalizes the values in a nested dictionary using z-score statistics.\n",
    "    Handles single values and lists of values.\n",
    "\n",
    "    Args:\n",
    "        data_dict (dict): The nested dictionary with normalized values.\n",
    "                          Format: {smiles: {property: value or [values]}}\n",
    "        stats (dict): The dictionary containing mean and std for each property.\n",
    "                      Format: {property: {'mean': value, 'std': value}}\n",
    "\n",
    "    Returns:\n",
    "        dict: A new dictionary with unnormalized values.\n",
    "    \"\"\"\n",
    "    unnormalized_data = copy.deepcopy(data_dict)\n",
    "    \n",
    "    for smiles, properties in unnormalized_data.items():\n",
    "        for prop, indicies in properties.items():\n",
    "            for index, values in indicies.items():\n",
    "                try:\n",
    "                    mean = stats[prop]['mean']\n",
    "                    std = stats[prop]['std']\n",
    "                    # Check if the value is a list and iterate if so\n",
    "                    if isinstance(values, list):\n",
    "                        unnormalized_data[smiles][prop][index] = [\n",
    "                            (item * std) + mean for item in values\n",
    "                        ]\n",
    "                    \n",
    "                    else:\n",
    "                        # Apply the reverse z-score formula for a single value\n",
    "                        unnormalized_value = (values * std) + mean\n",
    "                        unnormalized_data[smiles][prop][index] = unnormalized_value\n",
    "\n",
    "                except KeyError:\n",
    "                    print(f\"Warning: Statistics not found for property '{prop}'. Skipping.\")\n",
    "                    # The original value (single or list) is kept\n",
    "                    unnormalized_data[smiles][prop] = value\n",
    "\n",
    "    return unnormalized_data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c21eaeb8",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Saved comparison plot for fn to plots\\fn_comparison.png\n",
      "Saved comparison plot for alpha to plots\\alpha_comparison.png\n",
      "Saved comparison plot for delta to plots\\delta_comparison.png\n",
      "Saved comparison plot for SP to plots\\SP_comparison.png\n",
      "Saved comparison plot for SB to plots\\SB_comparison.png\n",
      "Saved comparison plot for n to plots\\n_comparison.png\n",
      "Saved comparison plot for N_mol_cm3 to plots\\N_mol_cm3_comparison.png\n",
      "Saved comparison plot for SA to plots\\SA_comparison.png\n",
      "Saved comparison plot for ET30 to plots\\ET30_comparison.png\n",
      "Saved comparison plot for pi_star to plots\\pi_star_comparison.png\n",
      "Saved comparison plot for beta to plots\\beta_comparison.png\n",
      "Saved comparison plot for SdP to plots\\SdP_comparison.png\n"
     ]
    }
   ],
   "source": [
    "temp_unorm = unnormalize_dict_with_lists(temp_dict, norm_dict)\n",
    "results_unnorm = unnormalize_dict_with_lists(results_dict, norm_dict) \n",
    "\n",
    "compare_predictions_by_n(temp_dict['CCCC#N'],results_dict['CCCC#N'],\n",
    "\n",
    "                      ground_truth=true_values_dict_unorm['CCCC#N'], label1='template predictions', label2='scratch predictions')"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "marketing_masters",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.18"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
