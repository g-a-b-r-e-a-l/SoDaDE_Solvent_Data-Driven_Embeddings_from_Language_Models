{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 84,
   "id": "671b1170",
   "metadata": {},
   "outputs": [],
   "source": [
    "import json\n",
    "import pandas as pd\n",
    "import copy\n",
    "import numpy as np\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 157,
   "id": "7eba4deb",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'ET30': {'mean': 41.78074074074074, 'std': 7.192808351716445}, 'alpha': {'mean': 0.24287037037037038, 'std': 0.4369842507179892}, 'beta': {'mean': 0.43583333333333335, 'std': 0.29472662765133556}, 'pi_star': {'mean': 0.5897058823529412, 'std': 0.2639473990589902}, 'SA': {'mean': 0.1259194630872483, 'std': 0.21698369962375624}, 'SB': {'mean': 0.41759060402684567, 'std': 0.30223225840275103}, 'SP': {'mean': 0.7266174496644294, 'std': 0.08636132434197896}, 'SdP': {'mean': 0.5100536912751678, 'std': 0.3397320642449683}, 'N_mol_cm3': {'mean': 0.009754802259887006, 'std': 0.004920819417443173}, 'n': {'mean': 1.4358654929577466, 'std': 0.06159673594301312}, 'fn': {'mean': 0.2591721408450704, 'std': 0.037422473958837625}, 'delta': {'mean': 20.727083333333333, 'std': 4.862952950986547}}\n"
     ]
    }
   ],
   "source": [
    "with open('predict_properties/test_predictions.json', 'r') as res_file:\n",
    "        results_dict = json.load(res_file)\n",
    "\n",
    "with open('data/normalisation_stats.json', 'r') as norm_file:\n",
    "        norm_dict = json.load(norm_file)\n",
    "print(norm_dict)\n",
    "base_values = pd.read_csv('data/test_values.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 90,
   "id": "2a004324",
   "metadata": {},
   "outputs": [],
   "source": [
    "def avg_predictions(dictionary):\n",
    "    predictions_averaged = {}\n",
    "\n",
    "    for smiles, properties in dictionary.items():\n",
    "        predictions_averaged[smiles] = {}\n",
    "\n",
    "        for prop, indices in properties.items():\n",
    "            total_sum = 0\n",
    "            total_count = 0\n",
    "            \n",
    "            # Calculate the sum and count of all predictions\n",
    "            for index, prediction_list in indices.items():\n",
    "                total_sum += sum(prediction_list)\n",
    "                total_count += len(prediction_list)\n",
    "            \n",
    "            # Calculate the average, handling the case where total_count is zero to prevent division by zero\n",
    "            if total_count > 0:\n",
    "                average_prediction = total_sum / total_count\n",
    "            else:\n",
    "                average_prediction = 0 # or None, depending on desired behavior\n",
    "            \n",
    "            predictions_averaged[smiles][prop] = average_prediction\n",
    "    return predictions_averaged\n",
    "    \n",
    "predictions_averaged = avg_predictions(results_dict)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "48b6954b",
   "metadata": {},
   "outputs": [],
   "source": [
    "true_values_dict = {}\n",
    "\n",
    "# Use df.itertuples() for a memory-efficient way to iterate over DataFrame rows.\n",
    "# 'index=False' prevents the row index from being included in the tuple.\n",
    "for row in base_values.itertuples(index=False):\n",
    "    # The first element of the tuple is the SMILES string\n",
    "    smiles = row[1]\n",
    "    \n",
    "    # Initialize a new dictionary for this SMILES if it doesn't exist\n",
    "    if smiles not in true_values_dict:\n",
    "        true_values_dict[smiles] = {}\n",
    "        \n",
    "    # Iterate through the rest of the columns to get the properties and values\n",
    "    # We slice the row tuple from the second element (index 1) onwards.\n",
    "    # We also get the corresponding column names from df.columns, excluding 'SMILES'.\n",
    "    for prop_name, value in zip(base_values.columns[1:], row[1:]):\n",
    "        # Store the value in the nested dictionary\n",
    "        true_values_dict[smiles][prop_name] = value\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 89,
   "id": "81bd26e9",
   "metadata": {},
   "outputs": [],
   "source": [
    "def unnormalize_dict(data_dict, stats):\n",
    "    \"\"\"\n",
    "    Unnormalizes the values in a nested dictionary using z-score statistics.\n",
    "\n",
    "    Args:\n",
    "        data_dict (dict): The nested dictionary with normalized values.\n",
    "                          Format: {smiles: {property: value}}\n",
    "        stats (dict): The dictionary containing mean and std for each property.\n",
    "                      Format: {property: {'mean': value, 'std': value}}\n",
    "\n",
    "    Returns:\n",
    "        dict: A new dictionary with unnormalized values.\n",
    "    \"\"\"\n",
    "    unnormalized_data = copy.deepcopy(data_dict)\n",
    "    \n",
    "    # Iterate through each smiles string in the dictionary\n",
    "    for smiles, properties in unnormalized_data.items():\n",
    "        # Iterate through each property and its normalized value\n",
    "        for prop, value in properties.items():\n",
    "            try:\n",
    "                mean = stats[prop]['mean']\n",
    "                std = stats[prop]['std']\n",
    "                \n",
    "                # Apply the reverse z-score formula: x = (z * std) + mean\n",
    "                unnormalized_value = (value * std) + mean\n",
    "                \n",
    "                # Update the value in the new dictionary\n",
    "                unnormalized_data[smiles][prop] = unnormalized_value\n",
    "            except KeyError:\n",
    "                print(f\"Warning: Statistics not found for property '{prop}'. Skipping unnormalization for this property.\")\n",
    "                # If stats are not found, we keep the original value\n",
    "                unnormalized_data[smiles][prop] = value\n",
    "            \n",
    "    return unnormalized_data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 91,
   "id": "44aacf00",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Warning: Statistics not found for property 'SMILES'. Skipping unnormalization for this property.\n",
      "Warning: Statistics not found for property 'SMILES'. Skipping unnormalization for this property.\n",
      "Warning: Statistics not found for property 'SMILES'. Skipping unnormalization for this property.\n",
      "Warning: Statistics not found for property 'SMILES'. Skipping unnormalization for this property.\n",
      "Warning: Statistics not found for property 'SMILES'. Skipping unnormalization for this property.\n",
      "dict_keys(['CCCCC', 'C1CCOC1', 'CC(=O)c1ccccc1', 'CCOC=O', 'CCCCO'])\n"
     ]
    }
   ],
   "source": [
    "prediction_avg_unnorm = unnormalize_dict(predictions_averaged, norm_dict)\n",
    "true_values_dict_unorm = unnormalize_dict(true_values_dict, norm_dict)\n",
    "print(true_values_dict_unorm.keys())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 165,
   "id": "b9c40b63",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "delta                  0.744454\n",
      "SdP                    0.015733\n",
      "SB                     0.001985\n",
      "SA                     0.000095\n",
      "fn                     0.000070\n",
      "n                      0.000268\n",
      "SP                     0.001164\n",
      "N_mol_cm3              0.000001\n",
      "ET30                   1.245248\n",
      "beta                   0.008403\n",
      "pi_star                0.017029\n",
      "alpha                  0.000978\n",
      "Average_per_solvent    0.169619\n",
      "Name: Average_per_property, dtype: float64\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "\n",
    "def mse_dataframe_with_avgs(pred_dict, true_dict):\n",
    "    # Compute MSE table\n",
    "    data = {}\n",
    "    for smiles, pred_props in pred_dict.items():\n",
    "        data[smiles] = {}\n",
    "        for prop, pred_value in pred_props.items():\n",
    "            true_value = true_dict[smiles][prop]\n",
    "            mse = (pred_value - true_value) ** 2\n",
    "            data[smiles][prop] = mse\n",
    "    df = pd.DataFrame.from_dict(data, orient='index')\n",
    "    \n",
    "    # Add per-row mean (average MSE per solvent)\n",
    "    df[\"Average_per_solvent\"] = df.mean(axis=1)\n",
    "    \n",
    "    # Add per-column mean (average MSE per property)\n",
    "    avg_row = df.mean(axis=0)\n",
    "    \n",
    "    # The intersection of averages = overall average MSE\n",
    "    avg_row[\"Average_per_solvent\"] = avg_row.mean()\n",
    "    \n",
    "    # Append the averages row\n",
    "    df.loc[\"Average_per_property\"] = avg_row\n",
    "    \n",
    "    return df\n",
    "\n",
    "# Example usage:\n",
    "df_mse = mse_dataframe_with_avgs(prediction_avg_unnorm, true_values_dict_unorm)\n",
    "#print(df_mse)\n",
    "decoder_MSE = df_mse.iloc[5].copy()\n",
    "print(decoder_MSE)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 167,
   "id": "2815c591",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                         delta       SdP        SB        SA            fn  \\\n",
      "C1CCOC1               0.177700  0.056302  0.000602  0.000235  1.564750e-04   \n",
      "CCCCO                 0.331666  0.016388  0.003761  0.000034  2.495663e-07   \n",
      "CCCCC                 1.189663  0.005479  0.002056  0.000014  1.892873e-04   \n",
      "CCOC=O                2.121827  0.001238  0.003511  0.000086  7.772237e-07   \n",
      "CC(=O)c1ccccc1        0.035833  0.000376  0.000010  0.000085  1.573190e-05   \n",
      "Average_per_property  0.771338  0.015957  0.001988  0.000091  7.250421e-05   \n",
      "\n",
      "                                 n        SP     N_mol_cm3      ET30  \\\n",
      "C1CCOC1               6.605138e-04  0.000232  5.851446e-09  0.003651   \n",
      "CCCCO                 8.447491e-08  0.000322  1.037829e-06  0.272274   \n",
      "CCCCC                 6.461181e-04  0.005230  3.219535e-07  1.575431   \n",
      "CCOC=O                4.884155e-05  0.000029  2.501931e-06  0.029536   \n",
      "CC(=O)c1ccccc1        1.740383e-05  0.000072  3.034920e-06  4.232485   \n",
      "Average_per_property  2.745923e-04  0.001177  1.380497e-06  1.222676   \n",
      "\n",
      "                          beta   pi_star     alpha  Average_per_solvent  \n",
      "C1CCOC1               0.025668  0.018638  0.003525             0.023948  \n",
      "CCCCO                 0.001346  0.001624  0.000083             0.052292  \n",
      "CCCCC                 0.000114  0.062340  0.000244             0.236784  \n",
      "CCOC=O                0.012398  0.001977  0.000518             0.180931  \n",
      "CC(=O)c1ccccc1        0.002350  0.000200  0.000591             0.356003  \n",
      "Average_per_property  0.008375  0.016956  0.000992             0.169991  \n"
     ]
    }
   ],
   "source": [
    "with open('predict_properties/template_preds.json', 'r') as template_file:\n",
    "        temp_dict = json.load(template_file)\n",
    "temp_avg = avg_predictions(temp_dict)\n",
    "\n",
    "temp_unnorm = unnormalize_dict(temp_avg, norm_dict)\n",
    "df_mse_temp = mse_dataframe_with_avgs(temp_unnorm, true_values_dict_unorm)\n",
    "print(df_mse_temp)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 194,
   "id": "9db3c9d7",
   "metadata": {},
   "outputs": [],
   "source": [
    "import json\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "import os\n",
    "\n",
    "def compare_predictions_by_n(dict_1, dict_2, ground_truth=None,\n",
    "                             label1='Dataset 1', label2='Dataset 2', output_dir='plots'):\n",
    "    \"\"\"\n",
    "    Create plots comparing predictions for each property from two different datasets,\n",
    "    with optional ground truth values plotted as horizontal lines.\n",
    "\n",
    "    Args:\n",
    "        json_file_path1 (str): Path to the first JSON file containing the data\n",
    "        json_file_path2 (str): Path to the second JSON file containing the data\n",
    "        ground_truth (dict): Dictionary mapping property names to their ground truth values\n",
    "        label1 (str): Label for the first dataset (default: 'Dataset 1')\n",
    "        label2 (str): Label for the second dataset (default: 'Dataset 2')\n",
    "        output_dir (str): Directory to save the plots (default: 'plots')\n",
    "    \"\"\"\n",
    "    # Load data from both JSON files\n",
    "    data1 = dict_1\n",
    "    data2 = dict_2\n",
    "    plt.rcParams['font.size'] = 18\n",
    "\n",
    "    # Create output directory if it doesn't exist\n",
    "    os.makedirs(output_dir, exist_ok=True)\n",
    "\n",
    "    # Get all property names from both datasets\n",
    "    all_properties = set(data1.keys()) | set(data2.keys())\n",
    "\n",
    "    # Process each property\n",
    "    for property_name in all_properties:\n",
    "        plt.figure(figsize=(12, 8))\n",
    "\n",
    "        # Initialize variables to track x-axis range\n",
    "        all_n_values = []\n",
    "\n",
    "        # Process first dataset if property exists\n",
    "        if property_name in data1:\n",
    "            property_data1 = data1[property_name]\n",
    "\n",
    "            # Prepare data for plotting\n",
    "            n_values1 = []\n",
    "            means1 = []\n",
    "            std_devs1 = []\n",
    "            mins1 = []\n",
    "            maxs1 = []\n",
    "\n",
    "            # Sort n values numerically\n",
    "            sorted_ns1 = sorted(map(int, property_data1.keys()))\n",
    "\n",
    "            for n in sorted_ns1:\n",
    "                n_str = str(n)\n",
    "                values = property_data1[n_str]\n",
    "                n_values1.append(n)\n",
    "                means1.append(np.mean(values))\n",
    "                std_devs1.append(np.std(values))\n",
    "                mins1.append(min(values))\n",
    "                maxs1.append(max(values))\n",
    "\n",
    "            all_n_values.extend(n_values1)\n",
    "\n",
    "            # Plot first dataset\n",
    "            plt.errorbar(n_values1, means1, yerr=std_devs1, fmt='-o',\n",
    "                         capsize=5, capthick=5, label=f'{label1} Mean ± Std Dev',\n",
    "                         color=\"#dacb00\", alpha=0.8)\n",
    "\n",
    "            plt.fill_between(n_values1, mins1, maxs1, alpha=0.50,\n",
    "                             label=f'{label1} Min/Max Range', color='#dacb00')\n",
    "\n",
    "        # Process second dataset if property exists\n",
    "        if property_name in data2:\n",
    "            property_data2 = data2[property_name]\n",
    "\n",
    "            # Prepare data for plotting\n",
    "            n_values2 = []\n",
    "            means2 = []\n",
    "            std_devs2 = []\n",
    "            mins2 = []\n",
    "            maxs2 = []\n",
    "\n",
    "            # Sort n values numerically\n",
    "            sorted_ns2 = sorted(map(int, property_data2.keys()))\n",
    "\n",
    "            for n in sorted_ns2:\n",
    "                n_str = str(n)\n",
    "                values = property_data2[n_str]\n",
    "                n_values2.append(n)\n",
    "                means2.append(np.mean(values))\n",
    "                std_devs2.append(np.std(values))\n",
    "                mins2.append(min(values))\n",
    "                maxs2.append(max(values))\n",
    "\n",
    "            all_n_values.extend(n_values2)\n",
    "\n",
    "            # Plot second dataset\n",
    "            plt.errorbar(n_values2, means2, yerr=std_devs2, fmt='-s',\n",
    "                         capsize=5, capthick=5, label=f'{label2} Mean ± Std Dev',\n",
    "                         color=\"#010055\", alpha=0.8)\n",
    "\n",
    "            plt.fill_between(n_values2, mins2, maxs2, alpha=0.50,\n",
    "                             label=f'{label2} Min/Max Range', color='#010055')\n",
    "\n",
    "        # Plot ground truth if provided\n",
    "        if ground_truth and property_name in ground_truth:\n",
    "            # Get the range of x values to draw the line across the entire plot\n",
    "            x_range = sorted(set(all_n_values))\n",
    "            if x_range:\n",
    "                x_min, x_max = min(x_range), max(x_range)\n",
    "                # Add some padding to the line\n",
    "                x_padding =  0.5 #(x_max - x_min) * 0.05 if x_max > x_min else\n",
    "                x_line = [x_min - x_padding, x_max + x_padding]\n",
    "                y_line = [ground_truth[property_name], ground_truth[property_name]]\n",
    "\n",
    "                plt.plot(x_line, y_line, '--', color=\"#005ac0\", linewidth=5,\n",
    "                         label=f'Ground Truth ({ground_truth[property_name]:.3f})', alpha=0.8)\n",
    "\n",
    "        # Handle case where property only exists in one dataset\n",
    "        if property_name not in data1:\n",
    "            print(f\"Warning: Property '{property_name}' not found in {dict_1}\")\n",
    "        elif property_name not in data2:\n",
    "            print(f\"Warning: Property '{property_name}' not found in {dict_2}\")\n",
    "\n",
    "        # Handle case where ground truth is provided but property not found\n",
    "        if ground_truth and property_name not in ground_truth:\n",
    "            print(f\"Warning: Ground truth value for '{property_name}' not provided\")\n",
    "\n",
    "        # Customize plot\n",
    "        title = f'Prediction Comparison for {property_name} by Position n'\n",
    "        if ground_truth and property_name in ground_truth:\n",
    "            title += f' (Ground Truth: {ground_truth[property_name]:.3f})'\n",
    "        plt.title(title)\n",
    "        plt.xlabel('Prediction Position (n)')\n",
    "        plt.ylabel('Prediction Value')\n",
    "\n",
    "        # Set x-ticks to show all n values from both datasets\n",
    "        unique_n_values = sorted(set(all_n_values))\n",
    "        if unique_n_values:\n",
    "            plt.xticks(unique_n_values)\n",
    "        plt.grid(True, linestyle='--', alpha=0.6)\n",
    "\n",
    "        # Place the legend below the plot\n",
    "        plt.legend(bbox_to_anchor=(0.5, -0.25), loc='upper center', ncol=2)\n",
    "        \n",
    "        plt.tight_layout()\n",
    "\n",
    "        # Save plot\n",
    "        plot_filename = os.path.join(output_dir, f'{property_name}_comparison.png')\n",
    "        plt.savefig(plot_filename, bbox_inches='tight', dpi=300)\n",
    "        plt.close()\n",
    "\n",
    "        print(f'Saved comparison plot for {property_name} to {plot_filename}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 195,
   "id": "7bc4bc12",
   "metadata": {},
   "outputs": [],
   "source": [
    "import copy\n",
    "\n",
    "def unnormalize_dict_with_lists(data_dict, stats):\n",
    "    \"\"\"\n",
    "    Unnormalizes the values in a nested dictionary using z-score statistics.\n",
    "    Handles single values and lists of values.\n",
    "\n",
    "    Args:\n",
    "        data_dict (dict): The nested dictionary with normalized values.\n",
    "                          Format: {smiles: {property: value or [values]}}\n",
    "        stats (dict): The dictionary containing mean and std for each property.\n",
    "                      Format: {property: {'mean': value, 'std': value}}\n",
    "\n",
    "    Returns:\n",
    "        dict: A new dictionary with unnormalized values.\n",
    "    \"\"\"\n",
    "    unnormalized_data = copy.deepcopy(data_dict)\n",
    "    \n",
    "    for smiles, properties in unnormalized_data.items():\n",
    "        for prop, indicies in properties.items():\n",
    "            for index, values in indicies.items():\n",
    "                try:\n",
    "                    mean = stats[prop]['mean']\n",
    "                    std = stats[prop]['std']\n",
    "                    # Check if the value is a list and iterate if so\n",
    "                    if isinstance(values, list):\n",
    "                        unnormalized_data[smiles][prop][index] = [\n",
    "                            (item * std) + mean for item in values\n",
    "                        ]\n",
    "                    \n",
    "                    else:\n",
    "                        # Apply the reverse z-score formula for a single value\n",
    "                        unnormalized_value = (values * std) + mean\n",
    "                        unnormalized_data[smiles][prop][index] = unnormalized_value\n",
    "\n",
    "                except KeyError:\n",
    "                    print(f\"Warning: Statistics not found for property '{prop}'. Skipping.\")\n",
    "                    # The original value (single or list) is kept\n",
    "                    unnormalized_data[smiles][prop] = value\n",
    "\n",
    "    return unnormalized_data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 196,
   "id": "c21eaeb8",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Saved comparison plot for fn to plots\\fn_comparison.png\n",
      "Saved comparison plot for alpha to plots\\alpha_comparison.png\n",
      "Saved comparison plot for delta to plots\\delta_comparison.png\n",
      "Saved comparison plot for SP to plots\\SP_comparison.png\n",
      "Saved comparison plot for SB to plots\\SB_comparison.png\n",
      "Saved comparison plot for n to plots\\n_comparison.png\n",
      "Saved comparison plot for N_mol_cm3 to plots\\N_mol_cm3_comparison.png\n",
      "Saved comparison plot for SA to plots\\SA_comparison.png\n",
      "Saved comparison plot for ET30 to plots\\ET30_comparison.png\n",
      "Saved comparison plot for pi_star to plots\\pi_star_comparison.png\n",
      "Saved comparison plot for beta to plots\\beta_comparison.png\n",
      "Saved comparison plot for SdP to plots\\SdP_comparison.png\n"
     ]
    }
   ],
   "source": [
    "temp_unorm = unnormalize_dict_with_lists(temp_dict, norm_dict)\n",
    "results_unnorm = unnormalize_dict_with_lists(results_dict, norm_dict) \n",
    "\n",
    "compare_predictions_by_n(temp_unorm['CC(=O)c1ccccc1'],results_unnorm['CC(=O)c1ccccc1'],\n",
    "\n",
    "                      ground_truth=true_values_dict_unorm['CC(=O)c1ccccc1'], label1='template predictions', label2='scratch predictions')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 158,
   "id": "11bf766f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Index(['Predicted ET30', 'Predicted alpha', 'Predicted beta',\n",
      "       'Predicted pi_star', 'Predicted SA', 'Predicted SB', 'Predicted SP',\n",
      "       'Predicted SdP', 'Predicted N_mol_cm3', 'Predicted n', 'Predicted fn',\n",
      "       'Predicted delta', 'Canonical Solvent SMILES'],\n",
      "      dtype='object')\n",
      "0             CCCCC\n",
      "1           C1CCOC1\n",
      "2    CC(=O)c1ccccc1\n",
      "3            CCOC=O\n",
      "4             CCCCO\n",
      "Name: Canonical Solvent SMILES, dtype: object\n",
      "Index(['ET30', 'alpha', 'beta', 'pi_star', 'SA', 'SB', 'SP', 'SdP',\n",
      "       'N_mol_cm3', 'n', 'fn', 'delta', 'SMILES'],\n",
      "      dtype='object')\n"
     ]
    }
   ],
   "source": [
    "gp_preds = pd.read_csv('predict_properties\\predictions_gp_mean.csv')\n",
    "rf_preds = pd.read_csv('predict_properties\\predictions_rf_mean.csv')\n",
    "print(gp_preds.columns)\n",
    "print(gp_preds['Canonical Solvent SMILES'])\n",
    "def fix_columns(df):\n",
    "    col_list = df.columns.to_list()\n",
    "    new_colums = []\n",
    "    for i in col_list:\n",
    "        new_colums.append(i.split(\" \")[-1])\n",
    "    new_df = pd.DataFrame()\n",
    "    new_df[new_colums] = df[col_list]\n",
    "    return new_df\n",
    "\n",
    "new_gp = fix_columns(gp_preds)\n",
    "new_rf = fix_columns(rf_preds)\n",
    "\n",
    "\n",
    "print(new_gp.columns)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 162,
   "id": "d3fbfacc",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Warning: Column 'SMILES' not found in the normalization dictionary. Skipping unnormalization for this column.\n",
      "Warning: Column 'SMILES' not found in the normalization dictionary. Skipping unnormalization for this column.\n",
      "Warning: Column 'solvent' not found in the normalization dictionary. Skipping unnormalization for this column.\n",
      "Warning: Column 'SMILES' not found in the normalization dictionary. Skipping unnormalization for this column.\n",
      "dict_items([('mean', 20.727083333333333), ('std', 4.862952950986547)])\n",
      "0   -1.024847\n",
      "1    0.024913\n",
      "2   -0.254717\n",
      "3    0.011764\n",
      "4    0.431490\n",
      "Name: delta, dtype: float64\n",
      "0    15.743301\n",
      "1    20.848235\n",
      "2    19.488406\n",
      "3    20.784292\n",
      "4    22.825397\n",
      "Name: delta, dtype: float64\n",
      "0   -1.280515\n",
      "1   -0.355151\n",
      "2    0.014994\n",
      "3   -0.334588\n",
      "4    0.529085\n",
      "Name: delta, dtype: float64\n",
      "0    14.5\n",
      "1    19.0\n",
      "2    20.8\n",
      "3    19.1\n",
      "4    23.3\n",
      "Name: delta, dtype: float64\n"
     ]
    }
   ],
   "source": [
    "def unnormalize_data(df, normalization_dict):\n",
    "    \"\"\"\n",
    "    Unnormalizes the data in a pandas DataFrame using a dictionary of mean and std values.\n",
    "\n",
    "    Args:\n",
    "        df (pd.DataFrame): The DataFrame with normalized values.\n",
    "        normalization_dict (dict): A dictionary where keys are column names (properties)\n",
    "                                   and values are dictionaries containing 'mean' and 'std' keys.\n",
    "                                   Example: {'property_a': {'mean': 10, 'std': 2}}\n",
    "\n",
    "    Returns:\n",
    "        pd.DataFrame: A new DataFrame with the unnormalized values.\n",
    "    \"\"\"\n",
    "    # Create a copy of the DataFrame to avoid modifying the original one\n",
    "    unnormalized_df = df.copy()\n",
    "\n",
    "    # Iterate through each column in the DataFrame\n",
    "    for column in unnormalized_df.columns:\n",
    "        # Check if the column exists in the normalization dictionary\n",
    "        if column in normalization_dict:\n",
    "            # Retrieve the mean and standard deviation for the current column\n",
    "            mean_val = normalization_dict[column]['mean']\n",
    "            std_val = normalization_dict[column]['std']\n",
    "            \n",
    "            # Unnormalize the column using the formula: (normalized_value * std) + mean\n",
    "            unnormalized_df[column] = (unnormalized_df[column] * std_val) + mean_val\n",
    "        else:\n",
    "            # Optionally print a warning for columns not found in the dictionary\n",
    "            print(f\"Warning: Column '{column}' not found in the normalization dictionary. Skipping unnormalization for this column.\")\n",
    "    \n",
    "    return unnormalized_df\n",
    "\n",
    "unnorm_new_gp = unnormalize_data(new_gp, norm_dict)\n",
    "unnorm_new_rf = unnormalize_data(new_rf, norm_dict)\n",
    "unnorm_base_values = unnormalize_data(base_values, norm_dict )\n",
    "\n",
    "print(norm_dict['delta'].items())\n",
    "print(new_gp['delta'])\n",
    "print(unnorm_new_gp['delta'])\n",
    "print(base_values['delta'])\n",
    "print(unnorm_base_values['delta'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 166,
   "id": "eed6a254",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "=== CHECKING DATA SHAPES AND BASIC INFO ===\n",
      "base_values shape: (5, 14)\n",
      "unnorm_base_values shape: (5, 14)\n",
      "\n",
      "unnorm_base_values ET30 range: [31.00, 49.70]\n",
      "unnorm_base_values delta range: [14.50, 23.30]\n",
      "\n",
      "=== DEBUG: GP ===\n",
      "Prediction df shape: (5, 13)\n",
      "True df shape: (5, 14)\n",
      "Merged df shape: (5, 26)\n",
      "\n",
      "ET30:\n",
      "  Predicted - mean: 40.190584, std: 5.812396, range: [32.551032, 48.736266]\n",
      "  True      - mean: 39.920000, std: 6.763653, range: [31.000000, 49.700000]\n",
      "  First 3 comparisons:\n",
      "    Pred: 32.551032, True: 31.000000, Diff²: 2.405701\n",
      "    Pred: 38.531386, True: 37.400000, Diff²: 1.280033\n",
      "    Pred: 41.162043, True: 40.600000, Diff²: 0.315893\n",
      "\n",
      "delta:\n",
      "  Predicted - mean: 19.937926, std: 2.630562, range: [15.743301, 22.825397]\n",
      "  True      - mean: 19.340000, std: 3.217608, range: [14.500000, 23.300000]\n",
      "  First 3 comparisons:\n",
      "    Pred: 15.743301, True: 14.500000, Diff²: 1.545798\n",
      "    Pred: 20.848235, True: 19.000000, Diff²: 3.415974\n",
      "    Pred: 19.488406, True: 20.800000, Diff²: 1.720278\n",
      "\n",
      "GP MSEs:\n",
      "                    MSE\n",
      "Column                 \n",
      "ET30       1.158247e+00\n",
      "alpha      6.757116e-03\n",
      "beta       1.211611e-02\n",
      "pi_star    8.603249e-03\n",
      "SA         8.683826e-04\n",
      "SB         1.449162e-02\n",
      "SP         9.047971e-04\n",
      "SdP        1.303280e-02\n",
      "N_mol_cm3  6.300721e-07\n",
      "n          6.164044e-04\n",
      "fn         2.034588e-04\n",
      "delta      1.948827e+00\n",
      "\n",
      "=== DEBUG: RF ===\n",
      "Prediction df shape: (5, 13)\n",
      "True df shape: (5, 14)\n",
      "Merged df shape: (5, 26)\n",
      "\n",
      "ET30:\n",
      "  Predicted - mean: 40.289483, std: 5.502635, range: [35.290653, 49.375473]\n",
      "  True      - mean: 39.920000, std: 6.763653, range: [31.000000, 49.700000]\n",
      "  First 3 comparisons:\n",
      "    Pred: 35.290653, True: 31.000000, Diff²: 18.409706\n",
      "    Pred: 36.622470, True: 37.400000, Diff²: 0.604552\n",
      "    Pred: 39.943008, True: 40.600000, Diff²: 0.431638\n",
      "\n",
      "delta:\n",
      "  Predicted - mean: 19.609873, std: 2.023612, range: [17.494640, 22.598711]\n",
      "  True      - mean: 19.340000, std: 3.217608, range: [14.500000, 23.300000]\n",
      "  First 3 comparisons:\n",
      "    Pred: 17.494640, True: 14.500000, Diff²: 8.967867\n",
      "    Pred: 19.974735, True: 19.000000, Diff²: 0.950108\n",
      "    Pred: 20.008638, True: 20.800000, Diff²: 0.626253\n",
      "\n",
      "RF MSEs:\n",
      "                MSE\n",
      "Column             \n",
      "ET30       4.003866\n",
      "alpha      0.000438\n",
      "beta       0.023704\n",
      "pi_star    0.051538\n",
      "SA         0.000132\n",
      "SB         0.028001\n",
      "SP         0.003285\n",
      "SdP        0.029443\n",
      "N_mol_cm3  0.000002\n",
      "n          0.001326\n",
      "fn         0.000332\n",
      "delta      2.461394\n",
      "\n",
      "Corrected df_avg shape: (5, 12)\n",
      "\n",
      "=== DEBUG: Average ===\n",
      "Prediction df shape: (5, 13)\n",
      "True df shape: (5, 14)\n",
      "Merged df shape: (5, 26)\n",
      "\n",
      "ET30:\n",
      "  Predicted - mean: 41.780741, std: 0.000000, range: [41.780741, 41.780741]\n",
      "  True      - mean: 39.920000, std: 6.763653, range: [31.000000, 49.700000]\n",
      "  First 3 comparisons:\n",
      "    Pred: 41.780741, True: 31.000000, Diff²: 116.224371\n",
      "    Pred: 41.780741, True: 37.400000, Diff²: 19.190889\n",
      "    Pred: 41.780741, True: 40.600000, Diff²: 1.394149\n",
      "\n",
      "delta:\n",
      "  Predicted - mean: 20.727083, std: 0.000000, range: [20.727083, 20.727083]\n",
      "  True      - mean: 19.340000, std: 3.217608, range: [14.500000, 23.300000]\n",
      "  First 3 comparisons:\n",
      "    Pred: 20.727083, True: 14.500000, Diff²: 38.776567\n",
      "    Pred: 20.727083, True: 19.000000, Diff²: 2.982817\n",
      "    Pred: 20.727083, True: 20.800000, Diff²: 0.005317\n",
      "\n",
      "Average MSEs:\n",
      "                 MSE\n",
      "Column              \n",
      "ET30       40.059956\n",
      "alpha       0.114936\n",
      "beta        0.075004\n",
      "pi_star     0.111925\n",
      "SA          0.020108\n",
      "SB          0.061662\n",
      "SP          0.008339\n",
      "SdP         0.084817\n",
      "N_mol_cm3   0.000004\n",
      "n           0.004990\n",
      "fn          0.001306\n",
      "delta      10.206400\n",
      "\n",
      "=== NORMALIZATION DICT CHECK ===\n",
      "ET30 - mean: 41.780741\n",
      "ET30 - actual data mean: 39.920000\n",
      "ET30 - difference: 1.860741\n",
      "delta - mean: 20.727083\n",
      "delta - actual data mean: 19.340000\n",
      "delta - difference: 1.387083\n",
      "DECODER MSE delta                  0.744454\n",
      "SdP                    0.015733\n",
      "SB                     0.001985\n",
      "SA                     0.000095\n",
      "fn                     0.000070\n",
      "n                      0.000268\n",
      "SP                     0.001164\n",
      "N_mol_cm3              0.000001\n",
      "ET30                   1.245248\n",
      "beta                   0.008403\n",
      "pi_star                0.017029\n",
      "alpha                  0.000978\n",
      "Average_per_solvent    0.169619\n",
      "Name: Average_per_property, dtype: float64\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "from sklearn.metrics import mean_squared_error\n",
    "import numpy as np\n",
    "\n",
    "# Debug function to examine data before MSE calculation\n",
    "def debug_data_before_mse(df_prediction, df_true, columns_to_compare, name=\"\"):\n",
    "    print(f\"\\n=== DEBUG: {name} ===\")\n",
    "    print(f\"Prediction df shape: {df_prediction.shape}\")\n",
    "    print(f\"True df shape: {df_true.shape}\")\n",
    "    \n",
    "    # Merge to see what we're actually comparing\n",
    "    merged_df = pd.merge(df_prediction, df_true, on='SMILES', how='inner', suffixes=('_pred', '_true'))\n",
    "    print(f\"Merged df shape: {merged_df.shape}\")\n",
    "    \n",
    "    for col in ['ET30', 'delta']:  # Focus on problematic columns\n",
    "        if col in columns_to_compare:\n",
    "            pred_col = f\"{col}_pred\"\n",
    "            true_col = f\"{col}_true\"\n",
    "            \n",
    "            if pred_col in merged_df.columns and true_col in merged_df.columns:\n",
    "                pred_vals = merged_df[pred_col].dropna()\n",
    "                true_vals = merged_df[true_col].dropna()\n",
    "                \n",
    "                print(f\"\\n{col}:\")\n",
    "                print(f\"  Predicted - mean: {pred_vals.mean():.6f}, std: {pred_vals.std():.6f}, range: [{pred_vals.min():.6f}, {pred_vals.max():.6f}]\")\n",
    "                print(f\"  True      - mean: {true_vals.mean():.6f}, std: {true_vals.std():.6f}, range: [{true_vals.min():.6f}, {true_vals.max():.6f}]\")\n",
    "                \n",
    "                # Show first few values\n",
    "                common_idx = pred_vals.index.intersection(true_vals.index)[:3]\n",
    "                if len(common_idx) > 0:\n",
    "                    print(f\"  First 3 comparisons:\")\n",
    "                    for idx in common_idx:\n",
    "                        print(f\"    Pred: {pred_vals.loc[idx]:.6f}, True: {true_vals.loc[idx]:.6f}, Diff²: {(pred_vals.loc[idx] - true_vals.loc[idx])**2:.6f}\")\n",
    "\n",
    "def calculate_mse_by_smiles_debug(df_prediction, df_true, columns_to_compare, debug_name=\"\"):\n",
    "    \"\"\"\n",
    "    Enhanced MSE calculation with debugging information\n",
    "    \"\"\"\n",
    "    # Debug before processing\n",
    "    debug_data_before_mse(df_prediction, df_true, columns_to_compare, debug_name)\n",
    "    \n",
    "    # Create copies to avoid modifying original DataFrames\n",
    "    df_pred_copy = df_prediction.copy()\n",
    "    df_true_copy = df_true.copy()\n",
    "    \n",
    "    # Merge the two DataFrames on the 'SMILES' column\n",
    "    merged_df = pd.merge(\n",
    "        df_pred_copy,\n",
    "        df_true_copy,\n",
    "        on='SMILES',\n",
    "        how='inner',\n",
    "        suffixes=('_pred', '_true')\n",
    "    )\n",
    "\n",
    "    if merged_df.empty:\n",
    "        print(\"Warning: No matching 'SMILES' strings found in the two DataFrames.\")\n",
    "        return None\n",
    "\n",
    "    mse_results = {}\n",
    "    \n",
    "    for column_name in columns_to_compare:\n",
    "        prediction_column = f\"{column_name}_pred\"\n",
    "        true_column = f\"{column_name}_true\"\n",
    "\n",
    "        if prediction_column not in merged_df.columns or true_column not in merged_df.columns:\n",
    "            print(f\"Error: The specified column '{column_name}' was not found in both DataFrames. Skipping.\")\n",
    "            continue\n",
    "\n",
    "        # Extract values and handle NaN\n",
    "        y_pred = merged_df[prediction_column].dropna()\n",
    "        y_true = merged_df[true_column].dropna()\n",
    "        \n",
    "        # Ensure both series have the same index\n",
    "        common_index = y_pred.index.intersection(y_true.index)\n",
    "        if len(common_index) == 0:\n",
    "            print(f\"Warning: No valid data points for column '{column_name}'.\")\n",
    "            continue\n",
    "            \n",
    "        y_pred = y_pred.loc[common_index]\n",
    "        y_true = y_true.loc[common_index]\n",
    "\n",
    "        # Calculate MSE\n",
    "        mse = mean_squared_error(y_true, y_pred)\n",
    "        mse_results[column_name] = mse\n",
    "        \n",
    "        # Extra debug for problematic columns\n",
    "        if column_name in ['ET30', 'delta'] and mse > 1000:\n",
    "            print(f\"\\n*** HIGH MSE WARNING for {column_name}: {mse:.2f} ***\")\n",
    "            print(f\"Number of data points: {len(y_pred)}\")\n",
    "            print(f\"Max absolute difference: {np.abs(y_pred - y_true).max():.6f}\")\n",
    "\n",
    "    if mse_results:\n",
    "        mse_df = pd.DataFrame.from_dict(mse_results, orient='index', columns=['MSE'])\n",
    "        mse_df.index.name = 'Column'\n",
    "        return mse_df\n",
    "    else:\n",
    "        print(\"Warning: No MSE results calculated.\")\n",
    "        return None\n",
    "\n",
    "# Your existing code with debug versions\n",
    "compare_cols = ['ET30', 'alpha', 'beta', 'pi_star', 'SA', 'SB', 'SP', 'SdP', 'N_mol_cm3', 'n', 'fn', 'delta']\n",
    "\n",
    "print(\"=== CHECKING DATA SHAPES AND BASIC INFO ===\")\n",
    "print(f\"base_values shape: {base_values.shape}\")\n",
    "print(f\"unnorm_base_values shape: {unnorm_base_values.shape}\")\n",
    "\n",
    "# Check if unnorm_base_values has the expected ranges\n",
    "print(f\"\\nunnorm_base_values ET30 range: [{unnorm_base_values['ET30'].min():.2f}, {unnorm_base_values['ET30'].max():.2f}]\")\n",
    "print(f\"unnorm_base_values delta range: [{unnorm_base_values['delta'].min():.2f}, {unnorm_base_values['delta'].max():.2f}]\")\n",
    "\n",
    "gp_mses = calculate_mse_by_smiles_debug(unnorm_new_gp, unnorm_base_values, compare_cols, \"GP\")\n",
    "print(\"\\nGP MSEs:\")\n",
    "print(gp_mses)\n",
    "\n",
    "rf_mses = calculate_mse_by_smiles_debug(unnorm_new_rf, unnorm_base_values, compare_cols, \"RF\")\n",
    "print(\"\\nRF MSEs:\")\n",
    "print(rf_mses)\n",
    "\n",
    "# Fix the df_avg creation\n",
    "df_avg = pd.DataFrame()\n",
    "\n",
    "# Use unnorm_base_values length instead of base_values\n",
    "num_rows = len(unnorm_base_values)  # This was likely the issue!\n",
    "\n",
    "for column in norm_dict.keys():\n",
    "    if column in compare_cols:\n",
    "        df_avg[column] = [norm_dict[column]['mean']] * num_rows\n",
    "\n",
    "print(f\"\\nCorrected df_avg shape: {df_avg.shape}\")\n",
    "\n",
    "# Use unnorm_base_values SMILES\n",
    "df_avg['SMILES'] = unnorm_base_values[\"SMILES\"].values\n",
    "\n",
    "avg_mses = calculate_mse_by_smiles_debug(df_avg, unnorm_base_values, compare_cols, \"Average\")\n",
    "print('\\nAverage MSEs:')\n",
    "print(avg_mses)\n",
    "\n",
    "# Additional diagnostic: Check if normalization dict makes sense\n",
    "print(f\"\\n=== NORMALIZATION DICT CHECK ===\")\n",
    "for col in ['ET30', 'delta']:\n",
    "    if col in norm_dict:\n",
    "        print(f\"{col} - mean: {norm_dict[col]['mean']:.6f}\")\n",
    "        # Compare with actual data range\n",
    "        actual_mean = unnorm_base_values[col].mean()\n",
    "        print(f\"{col} - actual data mean: {actual_mean:.6f}\")\n",
    "        print(f\"{col} - difference: {abs(norm_dict[col]['mean'] - actual_mean):.6f}\")\n",
    "\n",
    "print('DECODER MSE', decoder_MSE)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "marketing_masters",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.18"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
